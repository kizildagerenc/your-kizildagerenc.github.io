
<html>
  <head>
    <title> Eren C. K&#305;z&#305;lda&#287; </title>
	<style type="text/css">
    		body{
    		    /* line-height: 1.5; */
    		    padding: 4em 1em;
    		    width:1000px;
    		    margin-left:auto;
    		    margin-right:auto;
		    font-size:1.05em;
    		}
		li{
 	   	    margin: .5em 0;
		}
	</style>
  </head>
  <body>
    <img src="images/eren.jpeg" style="float:right;height:250px" hspace="20px">
       <h1> Eren C. K&#305;z&#305;lda&#287; </h1>
<address>
e-mail : <a href="mailto:kizildag@mit.edu">kizildag@mit.edu </a>
</address>
    <p>
I am a final year PhD student in the <a class="hidelink" href="https://www.eecs.mit.edu/">Department of Electrical Engineering and Computer Science (EECS)</a>  at the <a class="hidelink" href="https://mit.edu">Massachusetts Institute of Technology (MIT)</a>, where I am very fortunate to be advised by <a class="hidelink" href="http://www.mit.edu/~gamarnik/home.html">Prof. David Gamarnik</a>. I am affiliated with the <a class="hidelink" href="https://lids.mit.edu/">Laboratory for Information and Decision Systems (LIDS)</a> and the <a class="hidelink" href="https://idss.mit.edu/">Institute for Data, Systems, and Society (IDSS)</a>. <b>You can find my CV <a href="files/ErenCV.pdf">here.</a></b>
    </p>
<b> I am thrillled to join the <a href="https://stat.columbia.edu/">Department of Statistics at Columbia University</a> as a Distinguished Postdoctoral Fellow in Fall 2022.</b>
<br>
    <p>

<h3>Research Interests</h3>
<p> My research revolves around problems in <I> high-dimensional statistics</i>, <i>theory of machine learning</i>, and <i>applied probability</i> with an emphasis on computational aspects. In particular, I would like to understand the fundamental computational limits of such problems by studying the regimes of apparent hardness where efficient algorithms cease to exist. This is often guided by the insights provided by statistical physics and spin glass theory.   
 </p>


<h3>News</h3>

<ul><li><p><b>April 2022</b>: I presented a <a href="files/PerceptronPoster.pdf">poster</a> on symmetric binary perceptron model at <a href="https://sdscon.mit.edu/">MIT Statistics and Data Science Conference (SDSCon)</a>
</p>


<li><p><b>March 2022</b>: I gave two talks at <a href="https://web.mit.edu/siam/www/">MIT SIAM Student Seminar</a> and <a href="https://www.math.uic.edu/persisting_utilities/seminars/view_seminar?id=6910">University of Illinois at Chicago, Combinatorics and Probability Seminar</a> on our work on algorithmic barriers in the symmetric binary perceptron model. Slides are available <a href="files/PerceptronTalk.pdf">here</a>.
</p>

<li><p><b>February 2022</b>: I gave a talk at <a href="https://lids.mit.edu/news-and-events/events/symmetric-binary-perceptron-model-algorithms-and-barriers">MIT LIDS and Statistics Tea Talk</a> on Overlap Gap Property in symmetric binary perceptron.
</p>


<li><p><b>January 2022</b>: I gave talks at <a href="https://theory.stanford.edu/theory_lunch/">Stanford CS Theory Lunch</a>, <a href="https://web.stanford.edu/group/it-forum/talks/">Stanford Information Theory Forum</a>, <a href="https://lidsconf.mit.edu/2022/program.html">MIT LIDS Student Conference</a>, and <a href="https://ee.bilkent.edu.tr/en/">Bilkent University, Electrical and Electronics Engineering Department</a>. Two of these talks were based on our forhcoming work on algorithmic barriers in the symmetric binary perceptron model, and slides are available <a href="files/PerceptronTalk.pdf">here</a>.
</p>

<li><p> <b>Fall 2021</b>: I am a long-term participant at the semester program <a href="https://simons.berkeley.edu/programs/si2021">Computational Complexity of Statistical Inference</a> in <a href="https://simons.berkeley.edu"> Simons Institute for the Theory of Computing</a> at the <a href="https://www.berkeley.edu/">University of California, Berkeley</a>. There, I am co-organizing a <a href="http://www.bricehuang.com/ogp.html">reading group</a> on the Overlap Gap Property (OGP) with <a href="http://www.bricehuang.com">Brice Huang</a>.
</p>


<li> <p> <b>October 2021</b>: David gave a talk on our ongoing work on algorithms and barriers in symmetric perceptron model with <a href="http://willperkins.org/">Will Perkins</a> and <a href="https://www.changjixu.com/">Changji Xu</a> in <a href="https://simons.berkeley.edu/workshops/si2021-2">Simons Institute workshop</a>. A recording is available <a href="https://simons.berkeley.edu/talks/curious-case-symmetric-binary-perceptron-model-algorithms-and-barriers">here</a>. 
</p>

<li> <p><b>October 2021</b>: I presented a <a href="files/cornell_poster.pdf">poster</a> in <a href="https://www.orie.cornell.edu/orie-events/young-researchers-workshop"> Cornell ORIE Young Researchers Workshop.</a></p>

<li>
<p>
	<b>Fall 2020</b>: I was a long-term participant at the semester program <a href="https://simons.berkeley.edu/programs/hd20">Probability, Geometry, and Computation in High Dimensions </a> in <a href="https://simons.berkeley.edu"> Simons Institute for the Theory of Computing</a> at the <a href="https://www.berkeley.edu/">University of California, Berkeley</a>.
</p>

</ul>

<h3>Publications</h3>
<ol reversed>

    <li>
      <a href="https://arxiv.org/abs/2203.15667"> Algorithms and Barriers in the Symmetric Binary Perceptron Model
</a>(<a href="files/PerceptronTalk.pdf">Slides</a>,<a href="files/PerceptronPoster.pdf">Poster</a>)
<br>
      <em>Preprint.</em>
<br>
       with David Gamarnik, Will Perkins, and Changji Xu.
      
  </li> 

 <li>
      <a href="https://arxiv.org/abs/2103.01887"> Self-Regularity of Non-Negative Output Weights for Overparameterized Two-Layer Neural Networks
</a>(<a href="files/ISIT2021.pdf">Slides</a>)
<br>
      <em>IEEE Transactions on Signal Processing.</em>
      <br> <a href="https://ieeexplore.ieee.org/abstract/document/9517811
">Conference version</a> in <I>IEEE International Symposium on Information Theory (ISIT)</I>, 2021
<br>
       with David Gamarnik and Ilias Zadik.
      
  </li>

 <li>
      <a href="https://arxiv.org/abs/2103.01369"> Algorithmic Obstructions in the Random Number Partitioning Problem (<a href="https://www.youtube.com/watch?v=xQolif3PvsQ&ab_channel=SNAPPSeminar">Talk by David</a>,<a href="files/cornell_poster.pdf">Poster</a>,<a href="files/OGPinNPP.pdf">Slides</a>)
</a>
<br>
      <em>Submitted.</em>
<br>
             with David Gamarnik.
      
  </li>

 <li>
      <a href="https://arxiv.org/abs/1912.01599"> Stationary Points of Shallow Neural Networks with Quadratic Activation Function  
</a>(<a href="https://www.youtube.com/watch?v=iQAur0NweGw&ab_channel=MachineLearningatMIT">MIT ML Tea Talk</a>,<a href="files/QuadraticTalk.pdf">Updated Slides</a>)
<br>
      <em>Submitted.</em>
<br>
             with David Gamarnik and Ilias Zadik.
      
  </li>


 <li>
      <a href="https://ieeexplore.ieee.org/document/9541171
"> Inference in High-Dimensional Linear Regression via Lattice Basis Reduction and Integer Relation Detection
</a>
<br>
      <em>IEEE Transactions on Information Theory.</em>
<br>
       with David Gamarnik and Ilias Zadik.
      
  </li>



 <li>
      <a href="https://arxiv.org/abs/1810.05907"> Computing the Partition Function of the Sherrington-Kirkpatrick Model is Hard on Average
</a>(<a href="https://2020.ieee-isit-virtual.org/presentation/lecture/computing-partition-function-sherrington-kirkpatrick-model-hard-average">Talk</a>,<a href="files/ISIT2020.pdf">Slides</a>)
<br>
      <em>Annals of Applied Probability.</em>
      <br> <a href="https://ieeexplore.ieee.org/document/9174373
">Conference version</a> in <I>IEEE International Symposium on Information Theory (ISIT)</I>, 2020
<br>
       with David Gamarnik.
      
  </li>

 <li>
      <a href="https://ieeexplore.ieee.org/document/8849681
"> High-Dimensional Linear Regression and Phase Retrieval via PSLQ Integer Relation Algorithm
</a>(<a href="files/ISIT2019.pdf">Slides</a>)
<br>
      <em>IEEE International Symposium on Information Theory (ISIT), 2019.</em>
<br>
       with David Gamarnik.
      
  </li>



 <li>
      <a href="https://arxiv.org/abs/2003.10523
"> Neural Networks and Polynomial Regression. Demystifying the Overparametrization Phenomena
</a>
<br>
      <em>Preprint.</em>
<br>
       with Matt Emschwiller, David Gamarnik, and Ilias Zadik.
      
  </li>
</ol>
  <h3> Other Biographical Notes </h3>
I earned my B.S. degree with highest honors (<I>summa cum
laude</i>) in <a href="https://ee.boun.edu.tr">electrical and electronics engineering</a> from <a href="http://www.boun.edu.tr/en_US">Bogazi&#231;i University</a>, Istanbul, Turkey in 2014; and my M.S. degree in EECS from MIT in 2017. I did experimental research on magnetic resonance imaging (MRI) for my <a href="https://dspace.mit.edu/handle/1721.1/108976">Master's thesis</a>. Part of my thesis work appeared in the <i>24th Annual Meeting of International Society for Magnetic Resonance in Medicine (ISMRM)</i>, Singapore, 2016; and received a <a href="https://www.ismrm.org/16/program_files/O61.htm"><i>summa cum laude</i> award</a> (top 5% of all submitted works). Slides of my talk is available <a href="files/ISMRM_Slides.pdf">here</a>. 
<br>
<br>
I am a proud graduate of <a href="https://en.wikipedia.org/wiki/Ankara_Science_High_School">Ankara Science High School (AFL)</a>, class of 2010.
</div>
</div>

	</body>
</html>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.6.0/jquery.min.js"></script>
<script>
$(document).ready(function(){
    $(".by-topic-btn").click(function(){
        console.log("Hi!")
        $(".by-year-view").hide()
        $(".by-topic-view").show()
    });
    $(".by-year-btn").click(function(){
        console.log("Hi year!")
        $(".by-topic-view").hide()
        $(".by-year-view").show()
    });
});
</script>
